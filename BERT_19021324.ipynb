{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_19021324.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+IhkNP7U0xmC3JXGFIw2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thienluc2017/BERT_19021324/blob/main/BERT_19021324.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-7gqbfjfWSD"
      },
      "source": [
        "MSV:19021324.\n",
        "\n",
        "Họ và tên :Lê Thiên Lực\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev7-e74HfUtd"
      },
      "source": [
        "# A - Introduction\n",
        "Overview\n",
        "BERT, or Bidirectional Embedding Representations from Transformers, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks.\n",
        "The academic paper can be found here: https://arxiv.org/abs/1810.04805.\n",
        "\n",
        "**Reference**:\n",
        "\n",
        "To understand BERT and learn how to implement BERT, I highly recommend reading the following sources:\n",
        "\n",
        "- Good explanation and visualization of BERT: [https://jalammar.github.io/illustrated-bert/](https://jalammar.github.io/illustrated-bert/)\n",
        "- How to finetune BERT models: https://towardsdatascience.com/how-to-train-bert-aaad00533168\n",
        "- Finetune notebook from HuggingFace: [https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/training.ipynb#scrollTo=R8NJ_RtIUz4l](https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/training.ipynb#scrollTo=R8NJ_RtIUz4l)\n",
        "- Implementation code(write by my UET mentor: Phi Hung Nguyen) : [https://colab.research.google.com/drive/1bBnyzCkj2Imdk5hrZ0OAOH1l8aDLF4YW?usp=sharing](https://colab.research.google.com/drive/1wdt7z8UcDla3EAjJXI-pxmqZEEB3ry4Z?usp=sharing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYoMO40TcS1K"
      },
      "source": [
        "# B - Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9ZUbCaqcdL-"
      },
      "source": [
        "## 1. Install dependences and load Essential Libraries\n",
        "- pytorch-lightning: a simple trainer to help you minize code base\n",
        "- transformers: library contains multiple BERT models\n",
        "- sentencepiece: a word-to-vect library with fast implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "862NAROoiEp8"
      },
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install tensorflow==1.15\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuLnZSdYOgB8",
        "outputId": "669aeb23-81f4-4b6e-82bf-79b101c94cf7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTHmM0IVe_3u"
      },
      "source": [
        "## 2. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqWWeJnkhRz0",
        "outputId": "be0a0128-23c5-4b25-e04b-58083ebe1af9"
      },
      "source": [
        "DATA_ROOT_DIR=\"/content/drive/MyDrive/shopee-sentiment\"\n",
        "!ls $DATA_ROOT_DIR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission.csv  train.csv\t\t       train.xlsx\n",
            "test.csv\t       train_preprocess.csv\n",
            "test_preprocess.csv    train_preprocess_unsegment.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWGAbwe9lDco"
      },
      "source": [
        "# include some dependence\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split, DataLoader, Dataset\n",
        "import pytorch_lightning as pl\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "#\n",
        "DATA_DIR = DATA_ROOT_DIR + '/train_preprocess_unsegment.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eQsNqYXplTwq",
        "outputId": "6a66d7c3-f039-4a92-f94d-62d4a0a4aac9"
      },
      "source": [
        "# Use pandas to read csv, this will return a excel like table data\n",
        "train = pd.read_csv(DATA_DIR, encoding='utf-8')\n",
        "train.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "      <th>preprocess_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19018</th>\n",
              "      <td>19018</td>\n",
              "      <td>02dd8a6a</td>\n",
              "      <td>Cuối tuần hẹn_hò người_yêu đến CGV là hợp_lí n...</td>\n",
              "      <td>1</td>\n",
              "      <td>cuối tuần hẹn hò người yêu đến cgv là hợp lí n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5919</th>\n",
              "      <td>5919</td>\n",
              "      <td>4934dfc5</td>\n",
              "      <td>Nghe nhân_viên giới_thiệu khúc bạch ngon lắm n...</td>\n",
              "      <td>1</td>\n",
              "      <td>nghe nhân viên giới thiệu khúc bạch ngon lắm n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23039</th>\n",
              "      <td>23039</td>\n",
              "      <td>0b0f0acc</td>\n",
              "      <td>Mình mua phần kem hủ gần 1 kg ở cửa_hàng này n...</td>\n",
              "      <td>1</td>\n",
              "      <td>mình mua phần kem hủ gần 1kg ở cửa hàng này nè...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24342</th>\n",
              "      <td>24342</td>\n",
              "      <td>9dcd0a53</td>\n",
              "      <td>Gọi đồ uống nóng thì nguội_ngắt . Gọi bánh thì...</td>\n",
              "      <td>0</td>\n",
              "      <td>gọi đồ uống nóng thì nguội ngắt gọi bánh thì c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9813</th>\n",
              "      <td>9813</td>\n",
              "      <td>9ecffca1</td>\n",
              "      <td>đồ uống ở đây khá ngon và giá cũng vô_cùng hợp...</td>\n",
              "      <td>1</td>\n",
              "      <td>đồ uống ở đây khá ngon và giá cũng vô cùng hợp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                    preprocess_text\n",
              "19018       19018  ...  cuối tuần hẹn hò người yêu đến cgv là hợp lí n...\n",
              "5919         5919  ...  nghe nhân viên giới thiệu khúc bạch ngon lắm n...\n",
              "23039       23039  ...  mình mua phần kem hủ gần 1kg ở cửa hàng này nè...\n",
              "24342       24342  ...  gọi đồ uống nóng thì nguội ngắt gọi bánh thì c...\n",
              "9813         9813  ...  đồ uống ở đây khá ngon và giá cũng vô cùng hợp...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqtCqEK_l0p2"
      },
      "source": [
        "We will randomly split the entire training data into two sets: a train set with 80% of the data and a validation set with 20% of the data. We will perform hyperparameter tuning using cross-validation on the train set and use the validation set to compare models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E5M9y5_mKbI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train.preprocess_text.values\n",
        "y = train.id.values\n",
        "\n",
        "X_train, X_val, y_train, y_val =\\\n",
        "    train_test_split(X, y, test_size=0.2, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng9fmpBgxLAV"
      },
      "source": [
        "### 2.3. Load Test Data\n",
        "The test data contains 4555 examples with no label. About 300 examples are non-complaining tweets. Our task is to identify their `id` and examine manually whether our results are correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qfCy0WQ0xNvx",
        "outputId": "c7add3e8-98a9-45bf-832e-3ca9e7c764ad"
      },
      "source": [
        "DATA_DIR = DATA_ROOT_DIR + '/test.csv'\n",
        "test_data = pd.read_csv(DATA_DIR, encoding='utf-8')\n",
        "test_data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>7cdc42a5</td>\n",
              "      <td>Được bạn bè rủ rê lên Phố Cổ chơi , lang thang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>857c755e</td>\n",
              "      <td>Nhìn từ ngoài vào thấy khá ấn tượng trong cách...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>6dc660b0</td>\n",
              "      <td>Quán nhỏ , chính xác là xe bánh mì kê thêm mấy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1183</th>\n",
              "      <td>28773101</td>\n",
              "      <td>cơ sở này hơi khó tìm vì lối vào đầu đường đầy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>935ab00c</td>\n",
              "      <td>Cái này hôm trước mình với bạn mình qua rồi nè...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                               text\n",
              "828   7cdc42a5  Được bạn bè rủ rê lên Phố Cổ chơi , lang thang...\n",
              "356   857c755e  Nhìn từ ngoài vào thấy khá ấn tượng trong cách...\n",
              "260   6dc660b0  Quán nhỏ , chính xác là xe bánh mì kê thêm mấy...\n",
              "1183  28773101  cơ sở này hơi khó tìm vì lối vào đầu đường đầy...\n",
              "1260  935ab00c  Cái này hôm trước mình với bạn mình qua rồi nè..."
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}